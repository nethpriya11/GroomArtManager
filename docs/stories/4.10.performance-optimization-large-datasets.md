# Story 4.10: Performance Optimization for Large Datasets

## Status

Draft

## Story

**As a** system,
**I want** reports to load quickly even with thousands of service logs,
**so that** the manager dashboard remains responsive.

## Acceptance Criteria

1. Financial Ledger implements pagination: Only 50 rows fetched per page (Firestore limit + cursor-based pagination)
2. Leaderboards limited to top 10 by default (expandable to "View All")
3. Firestore queries use indexes: barberId+status+createdAt, serviceId+status+createdAt
4. Aggregations (sums, counts) calculated server-side if possible, otherwise cached client-side
5. Real-time listeners use query filters to minimize data transfer (only approved logs, date range)
6. React Query caching: Report data cached for 5 minutes, only refetches if stale
7. Loading states: Skeleton screens while data loading (no blank page flicker)
8. Debounced search: Doesn't re-query on every keystroke
9. Lighthouse performance audit: Page load < 3 seconds on 3G network
10. E2E test with 1000+ service logs verifies page loads and sorts correctly

## Tasks / Subtasks

- [ ] Implement cursor-based pagination for Financial Ledger (AC: 1)
  - [ ] Use Firestore limit() and startAfter() for pagination
  - [ ] Fetch only 50 rows per page
  - [ ] Add ShadCN Pagination component with Previous/Next buttons
  - [ ] Track current page cursor in component state
- [ ] Implement "View All" expansion for Leaderboards (AC: 2)
  - [ ] Default display: Top 10 barbers/services
  - [ ] Add "View All" button below leaderboard
  - [ ] Expand to show all results when clicked
  - [ ] Change button to "Show Less" after expansion
- [ ] Create Firestore composite indexes (AC: 3)
  - [ ] Index: barberId + status + createdAt
  - [ ] Index: serviceId + status + createdAt
  - [ ] Define in firestore.indexes.json
  - [ ] Deploy indexes to Firestore via Firebase CLI
- [ ] Implement server-side aggregations (AC: 4)
  - [ ] Create API route: /api/reports/aggregate
  - [ ] Calculate sums and counts server-side using Firebase Admin SDK
  - [ ] Cache results for 5 minutes using in-memory cache or Vercel KV
  - [ ] Fall back to client-side if cache miss
- [ ] Optimize real-time listeners with query filters (AC: 5)
  - [ ] Add where('status', '==', 'approved') to all listeners
  - [ ] Add date range filters to listeners
  - [ ] Minimize data transfer by fetching only necessary documents
- [ ] Configure React Query caching (AC: 6)
  - [ ] Set staleTime: 5 minutes for report aggregations
  - [ ] Set staleTime: Infinity for real-time onSnapshot queries
  - [ ] Configure gcTime (garbage collection) for memory management
  - [ ] Only refetch when data is stale
- [ ] Add skeleton loading states (AC: 7)
  - [ ] Create Skeleton components for KPI cards, tables, leaderboards
  - [ ] Show skeletons during initial data fetch
  - [ ] Prevent blank page flicker on page load
  - [ ] Smooth transition from skeleton to actual content
- [ ] Implement debounced search (AC: 8)
  - [ ] Use useDebounce hook with 300ms delay
  - [ ] Prevent re-querying on every keystroke
  - [ ] Already covered in Story 4.7
- [ ] Run Lighthouse performance audit (AC: 9)
  - [ ] Test on throttled 3G network
  - [ ] Verify page load < 3 seconds
  - [ ] Optimize based on Lighthouse suggestions
  - [ ] Target Performance score: 90+
- [ ] Create E2E test with 1000+ service logs (AC: 10)
  - [ ] Seed Firebase Emulator with 1000+ test logs
  - [ ] Verify page loads and renders correctly
  - [ ] Verify sorting works with large dataset
  - [ ] Measure performance: page load, sort time, filter time

## Dev Notes

### Cursor-Based Pagination

[Source: architecture.md#Performance Optimization - Database]

**Firestore Pagination Pattern:**

```typescript
// hooks/useServiceLogsPaginated.ts
import {
  collection,
  query,
  where,
  orderBy,
  limit,
  startAfter,
  getDocs,
  QueryDocumentSnapshot,
} from 'firebase/firestore'

interface PaginationState {
  data: ServiceLog[]
  lastDoc: QueryDocumentSnapshot | null
  hasMore: boolean
  isLoading: boolean
}

function useServiceLogsPaginated(pageSize = 50) {
  const [pagination, setPagination] = useState<PaginationState>({
    data: [],
    lastDoc: null,
    hasMore: true,
    isLoading: false,
  })

  const fetchPage = async (startAfterDoc?: QueryDocumentSnapshot) => {
    setPagination((prev) => ({ ...prev, isLoading: true }))

    const constraints = [
      where('status', '==', 'approved'),
      orderBy('createdAt', 'desc'),
      limit(pageSize),
    ]

    if (startAfterDoc) {
      constraints.push(startAfter(startAfterDoc))
    }

    const q = query(collection(db, 'serviceLogs'), ...constraints)
    const snapshot = await getDocs(q)

    const logs = snapshot.docs.map((doc) => ({ id: doc.id, ...doc.data() }))
    const lastDoc = snapshot.docs[snapshot.docs.length - 1] || null
    const hasMore = snapshot.docs.length === pageSize

    setPagination({
      data: logs,
      lastDoc,
      hasMore,
      isLoading: false,
    })
  }

  const nextPage = () => {
    if (pagination.lastDoc && pagination.hasMore) {
      fetchPage(pagination.lastDoc)
    }
  }

  // Initial fetch
  useEffect(() => {
    fetchPage()
  }, [])

  return { ...pagination, nextPage, fetchPage }
}
```

**Pagination UI:**

```typescript
import { Pagination, PaginationContent, PaginationItem, PaginationNext, PaginationPrevious } from '@/components/ui/pagination';

function FinancialLedger() {
  const { data, hasMore, isLoading, nextPage, fetchPage } = useServiceLogsPaginated(50);
  const [currentPage, setCurrentPage] = useState(1);

  return (
    <>
      <Table>
        {/* Table content */}
      </Table>

      <Pagination>
        <PaginationContent>
          <PaginationItem>
            <PaginationPrevious
              onClick={() => {
                if (currentPage > 1) {
                  setCurrentPage(p => p - 1);
                  fetchPage(); // Re-fetch from beginning (or implement prev cursor tracking)
                }
              }}
              disabled={currentPage === 1}
            />
          </PaginationItem>

          <PaginationItem>
            Page {currentPage}
          </PaginationItem>

          <PaginationItem>
            <PaginationNext
              onClick={() => {
                setCurrentPage(p => p + 1);
                nextPage();
              }}
              disabled={!hasMore || isLoading}
            />
          </PaginationItem>
        </PaginationContent>
      </Pagination>
    </>
  );
}
```

**Note:** Firestore doesn't natively support "previous page" with cursor-based pagination. For full bidirectional pagination, you'd need to:

1. Track array of cursors for each page visited
2. Use startAt() instead of startAfter() for previous page
3. For MVP, consider "Load More" button instead of traditional pagination

### Leaderboard Expansion

[Source: architecture.md#Components]

**Expandable Leaderboard:**

```typescript
function TopBarbersLeaderboard({ barbers }: { barbers: BarberStats[] }) {
  const [expanded, setExpanded] = useState(false);
  const displayedBarbers = expanded ? barbers : barbers.slice(0, 10);

  return (
    <div>
      <Table>
        <TableHeader>
          <TableRow>
            <TableHead>Rank</TableHead>
            <TableHead>Barber</TableHead>
            <TableHead>Services</TableHead>
            <TableHead>Revenue</TableHead>
          </TableRow>
        </TableHeader>
        <TableBody>
          {displayedBarbers.map((barber, index) => (
            <TableRow key={barber.id}>
              <TableCell>#{index + 1}</TableCell>
              <TableCell>{barber.name}</TableCell>
              <TableCell>{barber.serviceCount}</TableCell>
              <TableCell>${barber.revenue.toFixed(2)}</TableCell>
            </TableRow>
          ))}
        </TableBody>
      </Table>

      {barbers.length > 10 && (
        <Button
          variant="ghost"
          onClick={() => setExpanded(!expanded)}
          className="w-full mt-2"
        >
          {expanded ? 'Show Less' : `View All (${barbers.length})`}
        </Button>
      )}
    </div>
  );
}
```

### Firestore Composite Indexes

[Source: architecture.md#Database - Firestore]

**firestore.indexes.json:**

```json
{
  "indexes": [
    {
      "collectionGroup": "serviceLogs",
      "queryScope": "COLLECTION",
      "fields": [
        { "fieldPath": "barberId", "order": "ASCENDING" },
        { "fieldPath": "status", "order": "ASCENDING" },
        { "fieldPath": "createdAt", "order": "DESCENDING" }
      ]
    },
    {
      "collectionGroup": "serviceLogs",
      "queryScope": "COLLECTION",
      "fields": [
        { "fieldPath": "serviceId", "order": "ASCENDING" },
        { "fieldPath": "status", "order": "ASCENDING" },
        { "fieldPath": "createdAt", "order": "DESCENDING" }
      ]
    },
    {
      "collectionGroup": "serviceLogs",
      "queryScope": "COLLECTION",
      "fields": [
        { "fieldPath": "status", "order": "ASCENDING" },
        { "fieldPath": "createdAt", "order": "DESCENDING" }
      ]
    }
  ],
  "fieldOverrides": []
}
```

**Deploy indexes:**

```bash
firebase deploy --only firestore:indexes
```

### Server-Side Aggregations with Caching

[Source: architecture.md#API Routes]

**API Route: /api/reports/aggregate:**

```typescript
// app/api/reports/aggregate/route.ts
import { NextRequest, NextResponse } from 'next/server'
import { adminDb } from '@/lib/firebase/admin'
import { verifyAuthToken } from '@/lib/auth/verify-token'

// In-memory cache (for demo; use Vercel KV or Redis in production)
const cache = new Map<string, { data: any; timestamp: number }>()
const CACHE_TTL = 5 * 60 * 1000 // 5 minutes

export async function POST(request: NextRequest) {
  try {
    // Verify manager auth
    const token = await verifyAuthToken(request)
    if (!token || token.role !== 'manager') {
      return NextResponse.json({ error: 'Unauthorized' }, { status: 401 })
    }

    const { startDate, endDate } = await request.json()

    // Check cache
    const cacheKey = `aggregate:${startDate}:${endDate}`
    const cached = cache.get(cacheKey)
    if (cached && Date.now() - cached.timestamp < CACHE_TTL) {
      return NextResponse.json({ ...cached.data, cached: true })
    }

    // Query Firestore
    const logsRef = adminDb.collection('serviceLogs')
    const snapshot = await logsRef
      .where('status', '==', 'approved')
      .where('createdAt', '>=', new Date(startDate))
      .where('createdAt', '<=', new Date(endDate))
      .get()

    // Calculate aggregations
    let totalRevenue = 0
    let totalCommissions = 0
    const barberStats = new Map<
      string,
      { revenue: number; count: number; name: string }
    >()
    const serviceStats = new Map<
      string,
      { revenue: number; count: number; name: string }
    >()

    snapshot.docs.forEach((doc) => {
      const log = doc.data()
      totalRevenue += log.price
      totalCommissions += log.commissionAmount

      // Aggregate by barber
      const barberData = barberStats.get(log.barberId) || {
        revenue: 0,
        count: 0,
        name: '',
      }
      barberData.revenue += log.price
      barberData.count += 1
      barberStats.set(log.barberId, barberData)

      // Aggregate by service
      const serviceData = serviceStats.get(log.serviceId) || {
        revenue: 0,
        count: 0,
        name: '',
      }
      serviceData.revenue += log.price
      serviceData.count += 1
      serviceStats.set(log.serviceId, serviceData)
    })

    const result = {
      totalRevenue,
      totalCommissions,
      netProfit: totalRevenue - totalCommissions,
      topBarbers: Array.from(barberStats.entries())
        .map(([id, stats]) => ({ barberId: id, ...stats }))
        .sort((a, b) => b.revenue - a.revenue)
        .slice(0, 10),
      topServices: Array.from(serviceStats.entries())
        .map(([id, stats]) => ({ serviceId: id, ...stats }))
        .sort((a, b) => b.revenue - a.revenue)
        .slice(0, 10),
    }

    // Cache result
    cache.set(cacheKey, { data: result, timestamp: Date.now() })

    return NextResponse.json(result)
  } catch (error) {
    console.error('Aggregation error:', error)
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    )
  }
}
```

**Client-side usage:**

```typescript
function useReportAggregation(dateRange: DateRange) {
  return useQuery({
    queryKey: ['reportAggregation', dateRange.from, dateRange.to],
    queryFn: async () => {
      const response = await fetch('/api/reports/aggregate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          startDate: dateRange.from.toISOString(),
          endDate: dateRange.to.toISOString(),
        }),
      })
      return response.json()
    },
    staleTime: 5 * 60 * 1000, // 5 minutes
    gcTime: 10 * 60 * 1000, // 10 minutes
  })
}
```

### React Query Caching Configuration

[Source: architecture.md#State Management - React Query]

**Query Client Setup:**

```typescript
// lib/react-query/queryClient.ts
import { QueryClient } from '@tanstack/react-query'

export const queryClient = new QueryClient({
  defaultOptions: {
    queries: {
      staleTime: 0, // Default: refetch on mount
      gcTime: 5 * 60 * 1000, // 5 minutes (previously cacheTime)
      retry: 1,
      refetchOnWindowFocus: false, // Prevent refetch on tab switch
    },
  },
})
```

**Per-Query Configuration:**

```typescript
// Real-time queries (onSnapshot)
useQuery({
  queryKey: ['serviceLogs', 'realtime'],
  queryFn: realtimeListener,
  staleTime: Infinity, // Never stale, listener provides updates
  gcTime: Infinity, // Keep in cache indefinitely while mounted
})

// Aggregation queries
useQuery({
  queryKey: ['reportAggregation', dateRange],
  queryFn: fetchAggregation,
  staleTime: 5 * 60 * 1000, // 5 minutes
  gcTime: 10 * 60 * 1000, // 10 minutes
})

// Static data (services, barbers)
useQuery({
  queryKey: ['services'],
  queryFn: fetchServices,
  staleTime: 10 * 60 * 1000, // 10 minutes
  gcTime: 30 * 60 * 1000, // 30 minutes
})
```

### Skeleton Loading States

[Source: architecture.md#Components - ShadCN UI]

**Skeleton Components:**

```typescript
import { Skeleton } from '@/components/ui/skeleton';

function KPICardSkeleton() {
  return (
    <Card>
      <CardHeader>
        <Skeleton className="h-4 w-24" /> {/* Label */}
      </CardHeader>
      <CardContent>
        <Skeleton className="h-10 w-32" /> {/* Value */}
      </CardContent>
    </Card>
  );
}

function TableSkeleton({ rows = 5, columns = 4 }) {
  return (
    <Table>
      <TableHeader>
        <TableRow>
          {Array.from({ length: columns }).map((_, i) => (
            <TableHead key={i}>
              <Skeleton className="h-4 w-20" />
            </TableHead>
          ))}
        </TableRow>
      </TableHeader>
      <TableBody>
        {Array.from({ length: rows }).map((_, i) => (
          <TableRow key={i}>
            {Array.from({ length: columns }).map((_, j) => (
              <TableCell key={j}>
                <Skeleton className="h-4 w-full" />
              </TableCell>
            ))}
          </TableRow>
        ))}
      </TableBody>
    </Table>
  );
}
```

**Usage:**

```typescript
function ReportsPage() {
  const { data: kpis, isLoading: kpisLoading } = useReportKPIs();
  const { data: logs, isLoading: logsLoading } = useServiceLogs();

  return (
    <div>
      <div className="grid grid-cols-3 gap-4">
        {kpisLoading ? (
          <>
            <KPICardSkeleton />
            <KPICardSkeleton />
            <KPICardSkeleton />
          </>
        ) : (
          <>
            <KPICard label="Total Revenue" value={kpis.revenue} />
            <KPICard label="Total Commissions" value={kpis.commissions} />
            <KPICard label="Net Profit" value={kpis.netProfit} />
          </>
        )}
      </div>

      {logsLoading ? (
        <TableSkeleton rows={10} columns={7} />
      ) : (
        <FinancialLedgerTable logs={logs} />
      )}
    </div>
  );
}
```

### Lighthouse Performance Optimization

[Source: architecture.md#Performance]

**Run Lighthouse Audit:**

```bash
# Install Lighthouse CLI
npm install -g lighthouse

# Run audit (throttled 3G)
lighthouse http://localhost:3000/manager/reports \
  --throttling-method=devtools \
  --throttling.cpuSlowdownMultiplier=4 \
  --output html \
  --output-path ./lighthouse-report.html
```

**Target Metrics:**

- **First Contentful Paint (FCP):** < 1.8s
- **Largest Contentful Paint (LCP):** < 2.5s
- **Time to Interactive (TTI):** < 3.8s
- **Total Blocking Time (TBT):** < 200ms
- **Cumulative Layout Shift (CLS):** < 0.1

**Optimization Techniques:**

1. **Code Splitting:** Use React.lazy() for report charts/visualizations
2. **Image Optimization:** Use Next.js Image component for avatars
3. **Font Optimization:** Preload critical fonts, use font-display: swap
4. **Bundle Size:** Tree-shake unused dependencies, analyze bundle with next/bundle-analyzer
5. **Preloading:** Add <link rel="preload"> for critical resources

### Testing

#### Unit Tests

[Source: architecture.md#Testing Strategy - Frontend Unit Tests]

**Test File:** `tests/unit/hooks/useServiceLogsPaginated.test.ts`

**Test Cases:**

```typescript
import { renderHook, waitFor } from '@testing-library/react'
import { useServiceLogsPaginated } from '@/hooks/useServiceLogsPaginated'

vi.mock('firebase/firestore')

describe('useServiceLogsPaginated', () => {
  it('fetches first page on mount', async () => {
    const mockLogs = Array.from({ length: 50 }, (_, i) => ({
      id: `log_${i}`,
      price: 25,
    }))
    vi.mocked(getDocs).mockResolvedValue({
      docs: mockLogs.map((log) => ({ id: log.id, data: () => log })),
    })

    const { result } = renderHook(() => useServiceLogsPaginated(50))

    await waitFor(() => expect(result.current.isLoading).toBe(false))

    expect(result.current.data).toHaveLength(50)
    expect(result.current.hasMore).toBe(true)
  })

  it('indicates no more pages when less than page size returned', async () => {
    const mockLogs = Array.from({ length: 30 }, (_, i) => ({
      id: `log_${i}`,
      price: 25,
    }))
    vi.mocked(getDocs).mockResolvedValue({
      docs: mockLogs.map((log) => ({ id: log.id, data: () => log })),
    })

    const { result } = renderHook(() => useServiceLogsPaginated(50))

    await waitFor(() => expect(result.current.isLoading).toBe(false))

    expect(result.current.hasMore).toBe(false)
  })

  it('fetches next page with cursor', async () => {
    const firstPage = Array.from({ length: 50 }, (_, i) => ({
      id: `log_${i}`,
      price: 25,
    }))
    const secondPage = Array.from({ length: 50 }, (_, i) => ({
      id: `log_${i + 50}`,
      price: 30,
    }))

    vi.mocked(getDocs)
      .mockResolvedValueOnce({
        docs: firstPage.map((log) => ({ id: log.id, data: () => log })),
      })
      .mockResolvedValueOnce({
        docs: secondPage.map((log) => ({ id: log.id, data: () => log })),
      })

    const { result } = renderHook(() => useServiceLogsPaginated(50))

    await waitFor(() => expect(result.current.isLoading).toBe(false))

    // Fetch next page
    act(() => result.current.nextPage())

    await waitFor(() => expect(result.current.data).toHaveLength(50))
    expect(result.current.data[0].id).toBe('log_50')
  })
})
```

#### E2E Tests with Large Dataset

[Source: architecture.md#Testing Strategy - E2E Tests]

**Test File:** `tests/e2e/performance.spec.ts`

**Test Cases:**

```typescript
import { test, expect } from '@playwright/test'

test.describe('Performance with Large Datasets', () => {
  test.beforeAll(async () => {
    // Seed Firebase Emulator with 1000+ service logs
    // This would be done via Firebase Admin SDK in test setup
    // See: tests/fixtures/seed-large-dataset.ts
  })

  test('reports page loads in under 3 seconds', async ({ page }) => {
    const startTime = Date.now()

    await page.goto('/login')
    await page.click('text=Manager')
    await page.goto('/manager/reports')

    // Wait for content to be visible (not skeleton)
    await expect(page.locator('text=Total Revenue')).toBeVisible()
    await expect(page.locator('table tbody tr').first()).toBeVisible()

    const loadTime = Date.now() - startTime

    expect(loadTime).toBeLessThan(3000) // 3 seconds
  })

  test('financial ledger renders with pagination (1000+ logs)', async ({
    page,
  }) => {
    await page.goto('/login')
    await page.click('text=Manager')
    await page.goto('/manager/reports')

    // Verify only 50 rows displayed (pagination)
    await expect(page.locator('table tbody tr')).toHaveCount(50)

    // Verify pagination controls present
    await expect(page.locator('button:has-text("Next")')).toBeVisible()
  })

  test('sorts large table in under 100ms', async ({ page }) => {
    await page.goto('/manager/reports')

    const startTime = Date.now()

    // Click sort header
    await page.click('th:has-text("Price")')

    // Wait for table to update
    await page.waitForTimeout(100)

    const sortTime = Date.now() - startTime

    // Verify table sorted
    const rows = page.locator('table tbody tr')
    await expect(rows.first()).toBeVisible()

    expect(sortTime).toBeLessThan(100) // 100ms
  })

  test('filters by date range with 1000+ logs', async ({ page }) => {
    await page.goto('/manager/reports')

    // Apply date filter
    await page.click('text=Last 7 Days')

    // Wait for filter to apply
    await page.waitForTimeout(500)

    // Verify results filtered
    await expect(page.locator('table tbody tr')).not.toHaveCount(0)

    // Verify KPIs updated
    await expect(page.locator('text=Total Revenue')).toBeVisible()
  })

  test('searches ledger with 1000+ logs', async ({ page }) => {
    await page.goto('/manager/reports')

    // Search
    await page.fill('[placeholder*="Search"]', 'john')
    await page.waitForTimeout(350) // Debounce

    // Verify results
    await expect(page.locator('table tbody tr')).not.toHaveCount(0)

    // Verify all results contain "john"
    const firstRow = page.locator('table tbody tr').first()
    await expect(firstRow).toContainText(/john/i)
  })

  test('handles real-time updates with large dataset', async ({
    page,
    context,
  }) => {
    await page.goto('/manager/reports')

    // Get initial count
    const initialCount = await page.locator('table tbody tr').count()

    // Open barber page
    const barberPage = await context.newPage()
    await barberPage.goto('/login')
    await barberPage.click('text=Barber')
    await barberPage.click('text=John Barber')

    // Log service
    await barberPage.click('text=Haircut')
    await barberPage.click('button:has-text("Log 1 Service")')

    // Approve service
    await page.click('text=Pending Approvals')
    await page.click('[aria-label="Approve"]').first()

    // Navigate back to ledger
    await page.goto('/manager/reports')

    // Verify new log appears
    await expect(page.locator('table tbody tr')).toHaveCount(initialCount + 1)

    await barberPage.close()
  })

  test('Lighthouse performance score > 90', async ({ page }) => {
    // This test would use Lighthouse programmatically
    // See: https://github.com/GoogleChrome/lighthouse/blob/master/docs/readme.md#using-programmatically

    await page.goto('/manager/reports')

    // Run Lighthouse
    const lighthouse = await import('lighthouse')
    const { lhr } = await lighthouse.default(page.url(), {
      port: new URL(page.url()).port,
      output: 'json',
      throttlingMethod: 'devtools',
    })

    expect(lhr.categories.performance.score).toBeGreaterThan(0.9) // 90+
  })
})
```

#### Integration Tests

**Test that performance optimizations:**

- Pagination works correctly with cursor navigation
- Leaderboard expansion doesn't cause re-fetch
- Server-side aggregations return correct results
- Cache invalidation works (refetch after 5 minutes)
- Skeleton loading states display during data fetch
- React Query cache reduces redundant Firestore queries

## Change Log

| Date       | Version | Description            | Author          |
| ---------- | ------- | ---------------------- | --------------- |
| 2025-10-10 | v1.0    | Initial story creation | PM Agent (John) |

## Dev Agent Record

### Agent Model Used

{To be populated by dev agent}

### Debug Log References

{To be populated by dev agent}

### Completion Notes List

{To be populated by dev agent}

### File List

{To be populated by dev agent}

## QA Results

{To be populated by QA agent}
